{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BdDxzQU_AVVS"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import torch\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from transformers import XLMRobertaTokenizerFast\n",
        "from transformers import XLMRobertaForTokenClassification\n",
        "\n",
        "from transformers import Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoEKekh1Kgmp"
      },
      "source": [
        "# DE only Fine-Tuned Model (DFT) vs. DE-EN Bilingual Fine-Tuned Model (DEFT) vs. Code-Mixed Model (CMM) auf Rap Dataset (RAP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_xGUG8f6y0P"
      },
      "source": [
        "# RAP Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMTlL-Co3Ygn",
        "outputId": "0c331b12-62c6-495e-fe66-80ff286c9960"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(['immer', 'mit', 'der', 'family', ',', 'du', 'denkst', ',', 'ich', 'komm', 'aus', 'quahog'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['sie', 'wollen', 'den', 'cumshot', 'nicht', 'teilen', ',', 'also', 'spritz', 'ich', 'straight', 'in', 'den', 'deckenventilator', '.'], ['n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['fick', 'ich', 'sie', 'in', 'den', 'arsch', 'bin', 'ich', 'bei', '7,80', 'euro', '.'], ['B-B', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['und', 'alle', 'bitches', 'tanzen', ',', 'ja', ',', 'ich', 'lass', 'die', 'bitches', 'tanzen', 'uff', '.'], ['n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n'])\n",
            "(['guck', ',', 'jetzt', 'mach', 'ich', 'money', ',', 'viel', 'patte', ',', 'geb', 'es', 'papa', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['renn', 'weg', ',', 'bevor', 'sich', 'bullets', 'in', 'deinen', 'schädel', 'bohrn', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['z', 'rappt', 'so', 'perfekt', ',', 'es', 'ist', 'z', ',', 'motherfucker', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['kopf', 'ist', 'wieder', 'kafa', ',', 'bin', 'berliner', 'motherfucker', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['das', 'acht', 'zum', 'motherfucking', 'vier', ',', 'der', 'krasseste', 'auf', 'beats', '.'], ['n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['im', 'porsche-jeep', 'auf', 'kokain', ',', 'alle', 'motherfucker', 'wollen', 'groß', 'verdienen', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n'])\n",
            "(['mbeezy', 'sitzt', 'in', 'der', 'booth', 'und', 'droppt', 'nen', 'kleinen', 'freesy-stylie', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "([\"rock'n\", 'roll', 'heute', 'bin', 'ich', 'nicht', 'mehr', 'broke', ',', 'volles', 'risiko'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['ich', 'fick', 'diesen', 'kleinen', ',', 'dummen', 'bastard', ',', 'alter', ',', 'capital', '.'], ['n', 'B-B', 'n', 'n', 'n', 'B-B', 'B', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['capital', 'fickt', 'dich', ',', 'danach', 'deine', 'mom', 'und', 'bitch', '.'], ['n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['doch', 'ich', 'will', 'heut', 'nur', \"abhäng'n\", 'wie', 'die', 'bitchtits', 'von', 'rick', 'ross', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n'])\n",
            "(['yeah', ',', 'ganz', 'ehrlich', ',', 'acapella', ',', 'halbfinale', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['cash', 'rules', 'everything', 'around', 'me', 'alles', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['maxwell', 'top', 'level', '1a', 'stoffwechsel', '.'], ['n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['nuttensohn', ',', 'ich', 'baller', \"'\", 'dir', 'mit', 'der', 'gun', 'ins', 'gesicht', '.'], ['B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['sie', 'sagt', ',', 'ihr', \"geht's\", 'nicht', 'um', 'fame', ',', 'doch', 'ich', 'kann', 'nicht', 'kapieren', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['die', 'stimmung', 'ist', 'down', ',', 'ich', 'bin', 'schlecht', 'gelaunt', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['ich', 'trink', 'nur', 'safari', ',', 'bratan', ',', 'fick', 'auf', 'powerade', 'hahahaha', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n'])\n",
            "(['ey', ',', 'wie', 'kann', 'ich', 'hier', 'nur', 'diesen', 'hässlichen', 'krüppel', 'zerfetzen', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n'])\n",
            "(['bis', 'aus', 'euren', 'hurensohnköpfen', 'etwas', 'rotes', 'rausläuft', '.'], ['n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n'])\n",
            "(['yeah', ',', 'du', 'bist', 'chancenlos', 'auf', 'der', 'bühne', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['er', 'muss', 'ja', 'sein', 'face', 'die', 'ganze', 'zeit', 'unter', 'seiner', 'mütze', 'verstecken', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "([\"ging's\", 'mir', 'um', 'fame', ',', 'kolleg', ',', 'wär', 'ich', 'jetzt', 'bei', '385.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['eine', 'kugel', ',', 'sie', 'reicht', 'für', 'dich', 'sohn', 'einer', 'slut', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['die', 'kleine', 'bitch', 'findet', 'mich', 'geil', '.'], ['n', 'n', 'B-B', 'n', 'n', 'n', 'n'])\n",
            "(['wer', 'will', 'beef', 'mit', 'mir', '?', 'capital', ',', 'ich', 'ficke', 'alle', ',', 'alle', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n'])\n",
            "(['headshot', 'kennedy', ',', 'fick', 'deine', 'family', '.'], ['n', 'n', 'n', 'B-B', 'n', 'n', 'n'])\n",
            "(['und', 'wie', 'sie', 'alle', 'hießen', 'auf', \"dein'm\", 'weg', 'bis', 'ganz', 'nach', 'oben', ',', 'du', 'alte', 'snitch', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['ey', ',', 'euer', 'crewmaskottchen', 'ist', 'ein', 'blowjob', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['bitch', ',', 'ich', 'bin', 'fame', ',', 'fick', 'dein', 'kamerateam', '.'], ['B-B', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n'])\n",
            "(['radikal', 'sorge', 'ich', 'dafür', ',', 'dass', 'die', 'kleinen', 'wichser', 'bar', 'bezahlen', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n'])\n",
            "(['ihr', 'habt', 'gay', 'patentiert', ',', 'macht', 'auf', 'fuck', 'fake', 'friends', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n'])\n",
            "(['du', 'kriegst', 'schrotteile', 'ab', ',', 'nutte', ',', 'all', 'eyes', 'on', 'us', '.'], ['n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['jetzt', 'kommen', 'die', 'deutschrappenden', 'kings', ',', 'alles', 'andre', 'sind', 'nur', 'fotzen', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['bitches', 'auf', 'dem', 'beifahrersitz', '.'], ['B-B', 'n', 'n', 'n', 'n'])\n",
            "(['rapper', 'wollen', 'beef', '–', 'irgend', 'einen', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['this', 'is', 'z', ',', 'ich', 'bleib', \"'\", 'untergrund', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['ich', 'ficke', 'deinen', 'piss', 'fame', '!'], ['n', 'B-B', 'n', 'B-B', 'n', 'n'])\n",
            "(['deine', 'bitch', 'zu', 'ficken', 'kostet', 'mich', 'ne', 'autofahrt', '.'], ['n', 'B-B', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['all', 'the', 'way', 'up', 'aus', 'der', 'mittelschicht', 'ey', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['aber', 'er', 'sagt', ':', 'nein', ',', 'shit', ',', 'ich', 'hab', 'keinen', 'vater', 'parat', '!'], ['n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['ah', ',', 'jetzt', 'wird', 'deine', 'slut', 'gebumst', ',', 'sie', 'kriegt', 'meinen', 'schwanz', 'in', 'mund', '.'], ['n', 'n', 'n', 'n', 'n', 'B-B', 'B-B', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n'])\n",
            "(['bitch', 'lauf', ',', 'sonst', 'fick', 'ich', 'deine', 'bitch', 'auch', '.'], ['B-B', 'n', 'n', 'n', 'B-B', 'n', 'n', 'B-B', 'n', 'n'])\n",
            "(['ich', 'lieb', 'diesen', 'ghetto', 'scheiß', 'born', 'to', 'be', 'wild'], ['n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n'])\n",
            "(['alle', 'sind', 'auf', 'keep', 'it', 'real', 'unterwegs', 'keep', 'it', 'real', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['ich', 'ficke', 'dich', 'und', 'deine', 'mom', 'bei', 'fifa', '.'], ['n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['wolln', 'den', 'alten', 'mighty', 'wieder', ',', 'nicht', 'mehr', 'deep', ',', 'kein', 'problem', '!'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['nigga', ',', 'ich', 'pack', \"'\", 'heat', 'und', 'ich', 'bin', 'ready', 'für', 'den', 'krieg', '.'], ['B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['ich', 'geb', 'power', 'power', ',', 'hinter', 'mir', 'die', 'bras', 'wie', 'eine', 'mauer', 'ja', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['ich', 'bin', 'kaffer', ',', 'ich', 'bin', 'unübertreffbar', '.'], ['n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['du', 'und', 'deine', 'family', '?', 'schwuchtel', '!'], ['n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['ich', 'komm', 'mit', 'jungs', 'aus', 'stalingrad', ',', 'zeig', 'euch', 'wie', 'man', 'money', 'macht', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['yeah', ',', 'du', 'denkst', ',', 'du', 'wärst', 'ein', 'nigga', 'von', 'der', 'westcoast', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n'])\n",
            "(['push', 'die', 'preise', 'nach', 'oben', 'mit', 'reineren', 'drogen', 'drogen', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['bringt', 'dann', 'die', 'säcke', 'zum', 'kompost', 'und', 'blowt', 'den', 'prächtigen', 'boss-cock', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'B-B', 'n'])\n",
            "(['full', ',', 'das', 'ist', 'wahre', 'liebe', '!'], ['n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['mit', 'day-date', 'am', 'arm', 'in', 'der', 'u-bahn', 'fahren', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['wenn', 'ich', 'sterbe', ',', 'ja', ',', 'dann', 'hörn', 'sie', 'meine', 'lost', 'tapes', ',', 'ja', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['shit', 'ich', 'bin', 'boss', '.'], ['B-B', 'n', 'n', 'n', 'n'])\n",
            "(['bitches', ',', 'sie', 'finden', 'die', 'prolligen', 'arme', 'grauenvoll', 'wie', 'sonny', 'blacks', 'haare', '.'], ['B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['wir', 'habn', 'ein', 'movement', 'geprägt', ',', 'deutschraps', 'zukunft', 'geprägt', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['ich', 'schieb', 'mit', 'bitches', 'aus', 'dem', 'radio', 'nummern', '.'], ['n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['push', ',', 'push', 'bis', 'zur', 'cartier', 'push', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['rauche', 'cheese', ',', 'kein', 'gouda', ',', 'ja', 'nein', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['ah', ',', 'was', 'ist', 'das', 'für', 'ein', 'muschibattle', '?'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['polizeikontrolle', ',', 'kickdown', ',', 'was', 'solls', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['dein', 'chick', 'ist', 'ne', 'broke-ass-bitch', ',', 'denn', 'ich', 'fick', 'sie', ',', 'bis', 'ihr', 'steißbein', 'bricht', '.'], ['n', 'B-B', 'n', 'n', 'B-B', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['rapper', 'sind', 'im', 'erdgeschoss', ',', 'ah', ',', 'wir', 'sind', 'auf', 'dem', 'rooftop', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['du', 'ziehst', 'deinen', 'schwanz', 'und', 'fickst', 'wie', 'eine', 'hinterhältige', 'möse', '.'], ['n', 'n', 'n', 'B-B', 'n', 'B-B', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['dieser', 'boy', 'braucht', 'das', 'money', 'und', 'ein', 'bisschen', 'von', 'dem', 'fame', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['nako', 'is', 'king', ',', 'mutterficker', 'vergeben', '.'], ['n', 'n', 'n', 'n', 'B-B', 'n', 'n'])\n",
            "(['zu', 'fuß', 'gehen', 'ist', 'safer', 'als', 'n', 'beamer', 'zu', 'fahren', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['und', 'wenn', 'ich', 'deep', 'spit', 'nehmen', 'diese', 'ficker', 'mich', 'nicht', 'ernst', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n'])\n",
            "(['nur', 'noch', 'cash', 'in', \"mei'm\", 'head', ',', 'jeder', 'song', 'ist', 'ein', 'brett', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['easy', ',', 'kollege', ',', 'das', 'regeln', 'wir', 'ey', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['rap', 'am', 'mittwoch', ',', 'ich', 'fick', 'deine', 'bitch', 'doch', ',', 'ins', 'loch', '.'], ['n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['du', 'kannst', 'meinen', 'cock', 'blasen', '.'], ['n', 'n', 'n', 'B-B', 'B', 'n'])\n",
            "(['bitch', ',', 'ihr', 'seid', 'wack', ',', 'kein', 'respekt', 'vor', 'euch', ',', 'deutscher', 'rap', 'juckt', 'mich', \"ein'n\", 'scheißdreck', '.'], ['B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['cash', 'all-green', 'wie', 'ein', 'ganja-verkäufer', '.'], ['n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['der', 'hurensohn', 'hat', 'nix', 'zu', 'tun', '.'], ['n', 'B-B', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['ich', 'ficke', 'deinen', 'bitchbart', '!'], ['n', 'B-B', 'n', 'B-B', 'n'])\n",
            "(['capital', 'bra', ',', 'ich', 'komm', ',', 'ich', 'ficke', \"dein'n\", 'bitchrap', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'B-B', 'n'])\n",
            "(['du', 'denkst', ',', 'du', 'wärst', 'hier', 'fresh', 'der', 'held', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['was', 'für', 'bad-boys', '?', 'ihr', 'seid', 'dreckstoys', 'for', 'life', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n'])\n",
            "(['ich', 'guck', 'diese', 'nutte', 'an', ',', 'du', 'bist', 'whack', ',', 'bitch', '.'], ['n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['ich', 'zerhau', 'dich', 'pisser', ',', 'yeah', '!'], ['n', 'n', 'n', 'B-B', 'n', 'n', 'n'])\n",
            "(['fuck', 'mich', 'ab', 'und', 'ich', 'ficke', 'deine', 'schwangere', 'frau', '.'], ['B-B', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n'])\n",
            "(['hör', 'mal', 'zu', ',', 'du', 'schwanzlutscher', ',', 'mach', 'deine', 'hand', 'runter', '.'], ['n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['und', 'nochmal', 'chillen', 'mit', 'paar', 'vollidioten', ',', 'tankstelle', ',', 'ja', '.'], ['n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['wir', 'zwei', 'sind', 'ein', 'bündnis', 'for', 'life', ',', 'der', 'körper', 'klar', 'definiert'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['von', 'deiner', 'mutter', 'du', 'nuttensohn', '?'], ['n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['deine', 'mutter', 'will', 'mein', 'cock', 'und', 'zwar', 'zu', 'krass', '.'], ['n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['ey', ',', 'du', 'bist', 'so', 'scheiße', 'du', 'bist', 'n', 'hurenschleimer', '.'], ['n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['wenn', 'ich', 'komm', ',', 'motherfucker', ',', 'dann', 'bist', 'du', 'nur', 'flöten', '.'], ['n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['ich', 'zahle', 'gar', 'nix', ',', 'miese', 'punanis', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['69', ',', 'pussy', ',', 'suck', ',', 'facedrive', '.'], ['n', 'n', 'B-B', 'n', 'B-B', 'n', 'B-B', 'n'])\n",
            "(['okay', ',', 'du', 'kommst', 'gegen', 'meinen', 'bro', 'an', ',', 'er', 'ist', 'stoned', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['falscher', 'ort', ',', 'aber', 'richtiger', 'zeitpunkt', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['ja', ',', 'jetzt', 'steigt', 'deine', 'schlampe', 'ein', '.'], ['n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n'])\n",
            "(['ey', ',', 'yo', ',', 'dieser', 'bastard', 'sieht', 'wie', 'ein', 'homo', 'aus', '.'], ['n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'B-B', 'n', 'n'])\n",
            "(['der', 'drecksbulle', 'hält', 'mich', 'an', ',', 'ich', 'habe', 'nix', 'gestohln', '.'], ['n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['denn', 'hurensöhne', 'halten', 'fresse', 'wie', 'ein', 'pantomim', '.'], ['n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['nutte', ',', 'du', 'machst', 'auf', 'kanackenfreestyle', '.'], ['B-B', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['deine', 'mama', 'fragt', 'shit', ',', 'war', 'dein', 'vater', 'da', '?'], ['n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['ich', 'hab', 'den', 'nacken', 'voller', 'diamonds', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['was', 'isn', 'los', 'bei', 'dir', '?', 'ey', ',', 'ich', 'guck', 'deine', 'hoe', 'an', 'und', 'ich', 'krepier', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['du', 'bist', 'ne', 'richtige', 'hurentochter', '.'], ['n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['uh', ',', 'ah', ',', 'spotify-rich', '.'], ['n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['back', 'on', 'the', 'streets', ',', 'weil', 'das', 'feuer', 'grade', 'neu', 'entfacht', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['kirros', 'connecten', 'bis', 'prishtina', 'haha', '.'], ['n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['die', 'ganzen', 'wichser', 'wollen', 'ran', 'an', 'unsre', 'scheine', '.'], ['n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['deine', 'bitch', 'macht', 'einen', 'auf', 'treu', ',', 'doch', 'mittlerweile', 'fickt', 'die', 'torte', 'jeder', '.'], ['n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n'])\n",
            "(['i', 'love', 'you', 'enissa', 'amani', '.'], ['n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['so', 'viele', 'bitches', ',', 'die', 'mich', 'liken', 'na', 'na', 'na', 'na', '.'], ['n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['dein', 'schwanz', 'ist', 'über', 'miesen', ',', 'sick', ',', 'yo', '.'], ['n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['ach', ',', 'lass', 'die', 'huren', 'reden', ',', 'ich', 'will', 'ein', 'gutes', 'leben', '.'], ['n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['ja', ',', 'ich', 'weiß', ',', 'dass', 'du', 'das', 'alles', 'scheiße', 'findest', ',', 'aber', 'es', 'bleiben', 'bitches'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'B-B'])\n",
            "(['mein', 'fünfhunderter', 'macht', 'lärm', ',', 'weil', 'ich', 'aus', 'der', 'hood', 'komm', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['jeder', 'pisser', 'mit', 'nem', 'beat', 'träumt', 'vom', 'rapstarlife', '.'], ['n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['mit', 'disco-hoes', 'und', 'diskutieren', 'stundenlang', 'auf', 'whiskey-coke', '.'], ['n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['nutte', ',', 'ich', 'übernehm', 'das', 'business', ',', 'bro', ',', 'mit', 'sicken', 'flows', '.'], ['B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['macht', 'mal', 'lärm', 'für', 'den', 'coolen', 'motherfucker', '!'], ['n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['und', 'ich', 'gebe', 'keinen', 'fick', ',', 'denn', 'der', 'boy', 'ist', 'viel', 'zu', 'fly', '.'], ['n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['es', 'ist', 'z', ',', 'motherfucker', ',', 'der', 'in', 'deiner', 'fotze', 'brennt', ',', 'haha', '.'], ['n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n'])\n",
            "(['moscow', 'unterwelt', ',', 'welcome', 'in', 'the', 'rich', 'world', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['pussy', ',', 'bin', 'in', 'der', 'probezeit', 'nicht', 'drogenfrei', ',', 'sondern', 'sowas', 'von', 'high', '.'], ['B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['denn', 'ich', 'mache', 'es', 'viel', 'zu', 'easy', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n"
          ]
        }
      ],
      "source": [
        "csv_file_path = 'Labeled_dataset_rap.csv'\n",
        "\n",
        "sentences = {}\n",
        "with open(csv_file_path, 'r') as file:\n",
        "    csv_reader = csv.reader(file)\n",
        "    next(csv_reader)\n",
        "    for row in csv_reader:\n",
        "        sentence_id, token, label = row\n",
        "        if sentence_id not in sentences:\n",
        "            sentences[sentence_id] = {'tokens': [], 'labels': []}\n",
        "        sentences[sentence_id]['tokens'].append(token)\n",
        "        sentences[sentence_id]['labels'].append(label)\n",
        "\n",
        "result_rap = []\n",
        "for sentence_id, data in sentences.items():\n",
        "    words = data['tokens']\n",
        "    labels = data['labels']\n",
        "    result_rap.append((words, labels))\n",
        "\n",
        "for sentence in result_rap:\n",
        "    print(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LejAPKx4OhI",
        "outputId": "4ee14b28-1a3a-42ee-b4e8-88479ec9bb28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAP set length: 131\n"
          ]
        }
      ],
      "source": [
        "rap_data = result_rap\n",
        "print(f\"RAP set length: {len(rap_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W389DPzy4wFE",
        "outputId": "49f7aee3-6ef1-45a0-efa1-f0e81245afb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           terms\n",
            "0   hurentochter\n",
            "1      boss-cock\n",
            "2    scheißdreck\n",
            "3          nutte\n",
            "4         fotzen\n",
            "..           ...\n",
            "61       punanis\n",
            "62      schlampe\n",
            "63          slut\n",
            "64    schwuchtel\n",
            "65     bitchbart\n",
            "\n",
            "[66 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "gold_set_for_rap = set(word for (words, labels) in rap_data for word, label in zip(words, labels) if label == 'B-B' or label == 'B')\n",
        "\n",
        "df_gold_rap = pd.DataFrame({'terms': list(gold_set_for_rap)})\n",
        "print(df_gold_rap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "ZqhJY7sm5D2H"
      },
      "outputs": [],
      "source": [
        "rap_tags=[tup[1] for tup in rap_data]\n",
        "rap_texts=[tup[0] for tup in rap_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "xkvM8_WV5Qkb"
      },
      "outputs": [],
      "source": [
        "tokenizer = XLMRobertaTokenizerFast.from_pretrained(\"xlm-roberta-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "F7QyWWgd5jFg"
      },
      "outputs": [],
      "source": [
        "label_list=[\"n\", \"B-B\", \"B\"]\n",
        "label_to_id = {l: i for i, l in enumerate(label_list)}\n",
        "num_labels=len(label_list)\n",
        "\n",
        "def tokenize_and_align_labels(texts, tags):\n",
        "  tokenized_inputs = tokenizer(\n",
        "      texts,\n",
        "      padding=True,\n",
        "      truncation=True,\n",
        "      is_split_into_words=True,\n",
        "  )\n",
        "  labels = []\n",
        "  for i, label in enumerate(tags):\n",
        "      word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "      previous_word_idx = None\n",
        "      label_ids = []\n",
        "      for word_idx in word_ids:\n",
        "          if word_idx is None:\n",
        "              label_ids.append(-100)\n",
        "          elif word_idx != previous_word_idx:\n",
        "              label_ids.append(label_to_id[label[word_idx]])\n",
        "          else:\n",
        "              label_ids.append(-100)\n",
        "          previous_word_idx = word_idx\n",
        "\n",
        "      labels.append(label_ids)\n",
        "  tokenized_inputs[\"labels\"] = labels\n",
        "  return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "E4Ws-4Ag5nAO"
      },
      "outputs": [],
      "source": [
        "rap_input_and_labels = tokenize_and_align_labels(rap_texts, rap_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "GFwHrCnB5z8N"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "YMrmwfw95-dv"
      },
      "outputs": [],
      "source": [
        "rap_dataset = Dataset(rap_input_and_labels, rap_input_and_labels[\"labels\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "kTYOf43I6F0q"
      },
      "outputs": [],
      "source": [
        "def extract_terms(token_predictions, val_tokens):\n",
        "    extracted_terms = set()\n",
        "    for i in range(len(token_predictions)):\n",
        "        pred = token_predictions[i]\n",
        "        txt = val_tokens[i]\n",
        "        term = \"\"\n",
        "        inside_term = False\n",
        "        for j in range(len(pred)):\n",
        "            if pred[j] == \"B-B\" or pred[j] == \"B\":\n",
        "                if inside_term:\n",
        "                    extracted_terms.add(term)\n",
        "                    term = \"\"\n",
        "                    inside_term = False\n",
        "                term += txt[j]\n",
        "                inside_term = True\n",
        "            elif pred[j] == \"n\":\n",
        "                if inside_term:\n",
        "                    extracted_terms.add(term)\n",
        "                    term = \"\"\n",
        "                    inside_term = False\n",
        "        if inside_term:\n",
        "            extracted_terms.add(term)\n",
        "    return extracted_terms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "V1Uf0x1h6JrQ"
      },
      "outputs": [],
      "source": [
        "def compute_metrics_rap(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    extracted_terms = extract_terms(true_predictions, rap_texts)\n",
        "    extracted_terms = set([item.lower() for item in extracted_terms])\n",
        "\n",
        "    gold_set = set(word for (words, labels) in rap_data for word, label in zip(words, labels) if label == 'B-B' or label == 'B')\n",
        "\n",
        "    true_pos = extracted_terms.intersection(gold_set)\n",
        "    recall = len(true_pos) / len(gold_set) if len(gold_set) > 0 else 0\n",
        "    precision = len(true_pos) / len(extracted_terms) if len(extracted_terms) > 0 else 0\n",
        "\n",
        "    return {\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0Yms7TR68dT"
      },
      "source": [
        "# DFT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "ZpTB_KKQLyMK"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile('best_model_de.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/best_model_dft')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Ewy0K0Kq7HNr"
      },
      "outputs": [],
      "source": [
        "model = XLMRobertaForTokenClassification.from_pretrained(\"/content/best_model_dft\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Midxe4GL7Nqy"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    per_device_eval_batch_size=16,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    do_eval=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "JB1imvE17PxC"
      },
      "outputs": [],
      "source": [
        "trainer_dft = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        eval_dataset=rap_dataset,\n",
        "        compute_metrics=compute_metrics_rap,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "bFDtHvX37PrJ",
        "outputId": "b82732bf-37e0-4257-a2fa-4c79acce782b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluation results: {'eval_loss': 0.20088475942611694, 'eval_model_preparation_time': 0.0028, 'eval_precision': 0.6395348837209303, 'eval_recall': 0.8333333333333334, 'eval_f1': 0.7236842105263159, 'eval_runtime': 0.3423, 'eval_samples_per_second': 382.712, 'eval_steps_per_second': 26.293}\n"
          ]
        }
      ],
      "source": [
        "eval_results_dft = trainer_dft.evaluate()\n",
        "print(f\"evaluation results: {eval_results_dft}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "h9DwyQYf7khL",
        "outputId": "f43eafd0-bf94-4993-caf9-fa63c82cc4b9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "True: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "Predicted: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "True: ['n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "Predicted: ['n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "True: ['B-B', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "Predicted: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "True: ['n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n']\n",
            "Predicted: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n']\n",
            "True: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n"
          ]
        }
      ],
      "source": [
        "dft_predictions, dft_labels, dft_metrics = trainer_dft.predict(rap_dataset)\n",
        "\n",
        "dft_predictions = np.argmax(dft_predictions, axis=2)\n",
        "\n",
        "true_dft_predictions = [\n",
        "    [label_list[p] for (p, l) in zip(dft_prediction, dft_label) if l != -100]\n",
        "    for dft_prediction, dft_label in zip(dft_predictions, dft_labels)\n",
        "]\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"Predicted: {true_dft_predictions[i]}\")\n",
        "    print(f\"True: {[label_list[l] for l in dft_labels[i] if l != -100]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "MaYM3dPq7obB"
      },
      "outputs": [],
      "source": [
        "dft_extracted_terms = extract_terms(true_dft_predictions, rap_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwPYfTFw7rfT",
        "outputId": "97b5f29c-a36c-4603-b6fc-5905dd17ce3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'fotzen', 'krepier', 'zerhau', 'broke-ass-bitch', 'motherfucker', 'kaffer', 'nuttensohn', 'vollidioten', 'bitchrap', 'hoe', 'nigga', 'chick', 'flöten', 'nix', 'broke', 'diamonds', 'huren', 'arsch', 'schwuchtel', 'scheiße', 'blowjob', 'muschibattle', 'ficken', 'crewmaskottchen', 'mom', 'beef', 'sonny', 'spit', 'mutterficker', 'dreckstoys', 'punanis', 'schlampe', 'slut', 'mbeezy', 'suck', 'möse', 'gebumst', 'kanackenfreestyle', 'bitches', 'bullets', 'bitch', 'ficker', 'drecksbulle', 'freesy-stylie', 'vater', 'schrotteile', 'bratan', 'piss', 'scheiß', 'nacken', 'deep', 'blasen', 'krüppel', 'mighty', 'wack', 'hurenschleimer', 'pisser', 'fickst', 'whack', 'bitchbart', 'hurentochter', 'boss-cock', 'nutte', 'prishtina', 'steißbein', 'enissa', 'bitchtits', 'wichser', 'hurensohn', 'snitch', 'hurensohnköpfen', 'mauer', 'dummen', 'fickt', 'schwanz', 'fick', 'fly', 'ficke', 'schwanzlutscher', 'torte', 'hurensöhne', 'stoned', 'bastard', 'patte', 'miese', 'scheißdreck'}\n"
          ]
        }
      ],
      "source": [
        "print(dft_extracted_terms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "0MNvmp1I70kh"
      },
      "outputs": [],
      "source": [
        "def computeTermEvalMetrics(extracted_terms, gold_df):\n",
        "  extracted_terms = set([item.lower() for item in extracted_terms])\n",
        "  gold_set=set(gold_df)\n",
        "  true_pos=extracted_terms.intersection(gold_set)\n",
        "  recall=len(true_pos)/len(gold_set)\n",
        "  precision=len(true_pos)/len(extracted_terms)\n",
        "\n",
        "  print(\"Intersection\",len(true_pos))\n",
        "  print(\"Gold\",len(gold_set))\n",
        "  print(\"Extracted\",len(extracted_terms))\n",
        "  print(\"Recall:\", recall)\n",
        "  print(\"Precision:\", precision)\n",
        "  print(\"F1:\", 2*(precision*recall)/(precision+recall))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2Clrq1w7xag",
        "outputId": "11b15ba6-e041-472e-f3e1-d15d74f12ab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intersection 55\n",
            "Gold 66\n",
            "Extracted 86\n",
            "Recall: 0.8333333333333334\n",
            "Precision: 0.6395348837209303\n",
            "F1: 0.7236842105263159\n"
          ]
        }
      ],
      "source": [
        "computeTermEvalMetrics(dft_extracted_terms, gold_set_for_rap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0B9H4o-s77Tf"
      },
      "source": [
        "# DEFT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "Vj61xxtf73kY"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile('best_model_de-en.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/best_model_deft')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "fudb8QH48L_G"
      },
      "outputs": [],
      "source": [
        "model = XLMRobertaForTokenClassification.from_pretrained(\"/content/best_model_deft\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "T_i_tkSm8OYW"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    per_device_eval_batch_size=16,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    do_eval=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "FyoAztnQ8Qmo"
      },
      "outputs": [],
      "source": [
        "trainer_deft = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        eval_dataset=rap_dataset,\n",
        "        compute_metrics=compute_metrics_rap,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "QT6liy7U8Sge",
        "outputId": "a73e3e62-495a-4eec-cc2e-bbe9081826ff"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluation results: {'eval_loss': 0.09253334999084473, 'eval_model_preparation_time': 0.0056, 'eval_precision': 0.7380952380952381, 'eval_recall': 0.9393939393939394, 'eval_f1': 0.8266666666666667, 'eval_runtime': 0.3818, 'eval_samples_per_second': 343.088, 'eval_steps_per_second': 23.571}\n"
          ]
        }
      ],
      "source": [
        "eval_results_deft = trainer_deft.evaluate()\n",
        "print(f\"evaluation results: {eval_results_deft}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "-tVic-4J8Vyn",
        "outputId": "3131329a-876d-40f4-bf6b-3d31b70569b7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "True: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "Predicted: ['n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "True: ['n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "Predicted: ['B-B', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "True: ['B-B', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "Predicted: ['n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n']\n",
            "True: ['n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n']\n",
            "Predicted: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n']\n",
            "True: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n"
          ]
        }
      ],
      "source": [
        "deft_predictions, deft_labels, deft_metrics = trainer_deft.predict(rap_dataset)\n",
        "\n",
        "deft_predictions = np.argmax(deft_predictions, axis=2)\n",
        "\n",
        "true_deft_predictions = [\n",
        "    [label_list[p] for (p, l) in zip(deft_prediction, deft_label) if l != -100]\n",
        "    for deft_prediction, deft_label in zip(deft_predictions, deft_labels)\n",
        "]\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"Predicted: {true_deft_predictions[i]}\")\n",
        "    print(f\"True: {[label_list[l] for l in deft_labels[i] if l != -100]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "L3tD_MT98bRf"
      },
      "outputs": [],
      "source": [
        "deft_extracted_terms = extract_terms(true_deft_predictions, rap_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wkMwas68cOG",
        "outputId": "779fb71f-3239-49d2-f2bb-e8fefbffe009"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'fotzen', 'zerhau', 'ganja-verkäufer', 'broke-ass-bitch', 'motherfucker', 'kaffer', 'nuttensohn', 'vollidioten', 'kugel', 'bitchrap', 'hoe', 'nigga', 'chick', 'nix', 'huren', 'arsch', 'schwuchtel', 'scheiße', 'blowjob', 'homo', 'muschibattle', 'cock', 'ficken', 'dich', 'fotze', 'bras', 'spit', 'mutterficker', 'blowt', 'dreckstoys', 'punanis', 'schlampe', 'slut', 'mbeezy', 'möse', 'kanackenfreestyle', 'fuck', 'bitches', 'bullets', 'blacks', 'bitch', 'ficker', 'drecksbulle', 'freesy-stylie', 'bratan', 'piss', 'scheiß', 'bad-boys', 'nacken', 'blasen', 'geil', 'krüppel', 'pussy', 'mighty', 'hurenschleimer', 'pisser', 'fickst', 'lärm', 'whack', 'bitchbart', 'hurentochter', 'boss-cock', 'nutte', 'prishtina', 'steißbein', 'mich', 'bitchtits', 'wichser', 'hurensohn', 'cumshot', 'snitch', 'hurensohnköpfen', 'dummen', 'fickt', 'schwanz', 'motherfucking', 'fick', 'ficke', 'shit', 'schwanzlutscher', 'hurensöhne', 'bastard', 'patte', 'scheißdreck'}\n"
          ]
        }
      ],
      "source": [
        "print(deft_extracted_terms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wmhr_YZj8gJs",
        "outputId": "68755794-752d-49c4-d83a-e20e978e6879"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intersection 62\n",
            "Gold 66\n",
            "Extracted 84\n",
            "Recall: 0.9393939393939394\n",
            "Precision: 0.7380952380952381\n",
            "F1: 0.8266666666666667\n"
          ]
        }
      ],
      "source": [
        "computeTermEvalMetrics(deft_extracted_terms, gold_set_for_rap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LBGh_tgDLep"
      },
      "source": [
        "# CMM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8AGd9SQoDNJS"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile('best_model_cmm.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/best_model_cmm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "YJ63icb7DWmw"
      },
      "outputs": [],
      "source": [
        "model = XLMRobertaForTokenClassification.from_pretrained(\"/content/best_model_cmm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "dPOHArJ7DZin"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    per_device_eval_batch_size=16,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    do_eval=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "gPgzlFaMDcQF"
      },
      "outputs": [],
      "source": [
        "trainer_cmm = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        eval_dataset=rap_dataset,\n",
        "        compute_metrics=compute_metrics_rap,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "hboKj8nmDebR",
        "outputId": "351fca2d-4e50-4d46-dddd-19610894c371"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 00:18]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluation results: {'eval_loss': 0.24947714805603027, 'eval_model_preparation_time': 0.0053, 'eval_precision': 0.5526315789473685, 'eval_recall': 0.6363636363636364, 'eval_f1': 0.5915492957746479, 'eval_runtime': 0.3445, 'eval_samples_per_second': 380.231, 'eval_steps_per_second': 26.123}\n"
          ]
        }
      ],
      "source": [
        "eval_results_cmm = trainer_cmm.evaluate()\n",
        "print(f\"evaluation results: {eval_results_cmm}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "J6sBgstZDhEq",
        "outputId": "bb3c4620-711e-4429-e590-abee0cbbeb6d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "True: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "Predicted: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "True: ['n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "Predicted: ['n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "True: ['B-B', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "Predicted: ['n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'B-B', 'n', 'n']\n",
            "True: ['n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n']\n",
            "Predicted: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n']\n",
            "True: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n"
          ]
        }
      ],
      "source": [
        "cmm_predictions, cmm_labels, cmm_metrics = trainer_cmm.predict(rap_dataset)\n",
        "\n",
        "cmm_predictions = np.argmax(cmm_predictions, axis=2)\n",
        "\n",
        "true_cmm_predictions = [\n",
        "    [label_list[p] for (p, l) in zip(cmm_prediction, cmm_label) if l != -100]\n",
        "    for cmm_prediction, cmm_label in zip(cmm_predictions, cmm_labels)\n",
        "]\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"Predicted: {true_cmm_predictions[i]}\")\n",
        "    print(f\"True: {[label_list[l] for l in cmm_labels[i] if l != -100]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "lmo5kJx2DjIg"
      },
      "outputs": [],
      "source": [
        "cmm_extracted_terms = extract_terms(true_cmm_predictions, rap_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-IxzP_kDlLB",
        "outputId": "fbdf7a07-c16f-4b0e-c06a-4ed459fce255"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'tanzen', 'boss-cock', 'fotzen', 'scheiße', 'kleine', 'zerhau', 'krasseste', 'suck', 'fuck', 'bitches', 'steißbein', 'broke-ass-bitch', 'muschibattle', 'cock', 'motherfucker', 'krass', 'bitchtits', 'bullets', 'ficken', 'bitch', 'ficker', 'gouda', 'hurensohn', 'dich', 'snitch', 'nuttensohn', 'hurensohnköpfen', 'freesy-stylie', 'rapper', 'drecksbulle', 'whiskey-coke', 'schrotteile', 'kugel', 'bratan', 'bitchrap', 'dummen', 'piss', 'rauche', 'fickt', 'fotze', 'scheiß', 'ross', 'motherfucking', 'fick', 'nigga', 'facedrive', 'bras', 'flöten', 'deep', 'nix', 'boss', 'porsche-jeep', 'loch', 'broke', 'ficke', 'krüppel', 'halbfinale', 'shit', 'whack', 'pussy', 'diamonds', 'dreckstoys', 'torte', 'mighty', 'wack', 'hurenschleimer', 'bastard', 'pisser', 'arsch', 'schlampe', 'patte', 'slut', 'kickdown', 'brett', 'scheißdreck', 'bitchbart'}\n"
          ]
        }
      ],
      "source": [
        "print(cmm_extracted_terms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvC8edUbDnOM",
        "outputId": "0ca7ab43-3e15-41fe-a69e-c74ae565919e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intersection 42\n",
            "Gold 66\n",
            "Extracted 76\n",
            "Recall: 0.6363636363636364\n",
            "Precision: 0.5526315789473685\n",
            "F1: 0.5915492957746479\n"
          ]
        }
      ],
      "source": [
        "computeTermEvalMetrics(cmm_extracted_terms, gold_set_for_rap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjxwzGxs8-PF"
      },
      "source": [
        "# RESULTS:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGFj22nUEgRb"
      },
      "source": [
        "## DE Only Fine-Tuned Model (DFT):\n",
        "Recall: 0.8333333333333334\n",
        "Precision: 0.6395348837209303\n",
        "**F1: 0.7236842105263159**\n",
        "\n",
        "## DE-EN Bilingual Fine-Tuned Model (DEFT):\n",
        "Recall: 0.9393939393939394\n",
        "Precision: 0.7380952380952381\n",
        "**F1: 0.8266666666666667**\n",
        "\n",
        "## Code-Mixed Model (CMM):\n",
        "Recall: 0.6363636363636364\n",
        "Precision: 0.5526315789473685\n",
        "**F1: 0.5915492957746479**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxFjwNJKGuMM"
      },
      "source": [
        "# DE only Fine-Tuned Model (DFT) vs. DE-EN Bilingual Fine-Tuned Model (DEFT) vs. Code-Mixed Model (CMM) auf Cross-Domain Dataset (CDD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ywk8tXzcG-ew"
      },
      "source": [
        "# CDD Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DHWZoNDs1tZ",
        "outputId": "39958deb-5e22-431e-ca96-79c908ff05ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(['yeah', ',', 'zieh', 'den', 'carlo', 'aus', ',', 'du', 'nuttensohn', ',', 'sonny', 'bounct', 'den', 'beat', '–', 'mission', 'complete', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['politiker', 'sind', 'alles', 'abschaum', '!'], ['n', 'n', 'n', 'B-B', 'n'])\n",
            "(['haiti', 'like', 'ghetto-scheißlöcher', 'across', 'america', 'is', 'an', 'open', 'finanzkanalisation', 'throw', 'billions', 'at', 'the', 'place', 'and', 'you', 'will', 'not', 'even', 'see', 'where', 'the', 'geld', 'ging', 'weiß', 'do', 'not', 'have', 'the', 'stomach', 'to', 'rule', 'these', 'places', 'like', 'they', 'need', 'to', 'be', 'ruled', 'with', 'strongmen', '.'], ['n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['weswegen', 'hab', 'ich', 'immer', 'wieder', 'trouble', 'mit', 'den', 'cops', ',', 'raum', 'voller', 'bitches', ',', 'aber', 'trotzdem', 'bin', 'ich', 'lost', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['me', ',', 'myself', 'und', 'meine', 'dna', ',', 'versace-nutten', 'machen', 'blowjob', 'klar', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'B-B', 'n', 'n'])\n",
            "(['i', 'could', 'argue', 'that', 'calling', 'someone', 'a', 'pathetic', 'dumb', 'bitch', 'is', 'a', 'character', 'flaw', 'too', ',', 'but', 'i', 'really', 'think', 'that', 'character', 'is', 'much', 'easier', 'to', 'see', 'if', 'you', 'have', 'a', 'discussion', 'with', 'someone', 'about', 'what', 'they', 'mean', 'by', 'their', 'words', ',', 'even', 'if', 'they', 'do', \"n't\", 'choose', 'good', 'ones', 'in', 'the', 'first', 'place', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'B', 'B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['where', 'life', '4', 'me', 'was', \"n't\", 'always', 'good', ',', 'ich', 'weiß', ',', 'das', 'war', 'wack', 'und', 'weit', 'entfernt', 'vom', 'don', ',', 'doch', 'ich', 'hab', 'den', 'shit', 'als', 'erster', 'von', 'uns', 'ernst', 'genommen', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['nearly', 'all', 'her', 'fans', 'are', 'weiße', 'kaukasier', 'how', 'ironisch', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['scheißegal', ',', 'denn', 'was', 'raus', 'muss', ',', 'muss', 'raus', ',', 'ich', 'rechnete', 'ab', 'und', 'die', 'crowd', 'rastet', 'aus', '.'], ['B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['ich', 'überschwemme', 'diese', 'straßen', ',', 'crime', 'pays', ',', 'du', 'bist', 'ne', 'pussy', ',', 'du', 'weißt', ',', 'wovon', 'ich', 'rede', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['for', 'milliarden', 'menschen', 'jesus', 'let', 'the', 'mittlerer', 'osten', 'enslave', 'the', 'muslims', 'and', 'let', 'the', 'sandniggers', 'suffer', 'why', 'is', 'that', 'so', 'fucking', 'hard', 'to', 'grasp'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n'])\n",
            "(['fox', 'überträgt', 'halt', 'keine', 'unterhaus-debatten', 'und', 'was', 'anderes', 'guckt', 'der', 'trottel', 'ja', 'nicht', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n'])\n",
            "(['it', 'was', 'an', 'open', 'secret', 'in', 'the', 'wehrmacht', 'that', 'treating', 'the', 'slavs', 'in', 'poland', 'as', 'sub-human', 'was', 'acceptable', ',', 'in', 'fact', 'it', 'was', 'encouraged', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['genausowenig', 'möchten', 'die', 'allermeisten', 'afrodeutschen', 'nicht', 'als', 'mohr', 'oder', 'neger', 'bezeichnet', 'werden', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'B-B', 'n', 'n', 'n'])\n",
            "(['niemand', 'mag', 'klugscheisser', '.'], ['n', 'n', 'B-B', 'n'])\n",
            "(['tausend', 'rapper', 'saugen', \"für'n\", 'feature', 'pimmel', 'auf', 'klo', ',', 'ich', 'fick', 'fake', '\"', 'gangster', 'mc', \"'s\", 'and', 'make', 'em', 'faggot', 'flambe', '.'], ['n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n'])\n",
            "(['i', 'have', 'scheißhaut', 'and', 'my', 'gesichtsausdruck', 'always', 'so', 'red', 'and', 'to', 'be', 'honest', 'it', 'one', 'of', 'the', 'main', 'reasons', 'i', 'am', 'so', 'insecure', 'so', 'yeah', 'thanks', 'skin', '.'], ['n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['und', 'viele', 'haben', 'danach', 'dann', 'die', 'seite', 'geswitched', ',', 'das', 'war', 'der', 'punkt', ',', 'an', 'dem', 'ich', 'merkte', ',', 'life', 'ist', 'ne', 'bitch', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['laber', 'nicht', 'über', 'mich', ',', 'du', 'mistkind', ',', 'denn', 'you', 'do', \"n't\", 'know', 'me', 'and', 'you', 'do', \"n't\", 'know', 'wie', 'ich', 'bin', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['one', 'of', 'the', 'schwierigste', 'dinge', 'to', 'find', 'in', 'america', 'is', 'a', 'arzt', ',', 'der', 'is', 'not', 'a', 'nigger', 'sandnigger', 'spic', 'or', 'chink', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'B-B', 'B-B', 'n', 'B-B', 'n'])\n",
            "(['walk', 'up', 'to', 'a', 'broad', 'with', 'nice', 'dry', 'nuts', ',', 'get', 'her', 'fucking', 'number', 'and', 'talk', 'to', 'some', 'sluts', '!'], ['n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['dummkopf-schlampe', 'accurate', '.'], ['B-B', 'n', 'n'])\n",
            "(['just', 'want', 'to', 'add', 'that', 'there', 'is', 'a', 'culture', 'nowadays', 'that', 'slut', 'shames', 'the', 'girls', 'and', 'praises', 'the', 'men', 'in', 'these', 'situations', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['good', 'more', 'like', 'this', 'the', 'more', 'wildschweine', 'begrüßen', 'schwuchteln', 'that', 'get', 'gutted', 'like', 'fish', 'by', 'their', 'rapefugees', 'the', 'better', 'it', 'removes', 'the', 'fagtards', 'from', 'existence', 'and', 'it', 'may', 'actually', 'educate', 'survivors', 'as', 'to', 'the', 'stupidity', 'of', 'their', 'faggotry', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['import', 'von', 'subhumans', 'to', 'rape', 'weiße', 'frauen', 'and', 'children', 'and', 'torture', 'and', 'mord', 'weiße', 'männer', 'is', 'the', 'opposite', 'of', 'what', 'machthungrige', 'politiker', 'would', 'do', '.'], ['n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['you', 'are', 'right', 'about', 'it', 'being', 'zeit', 'amerikaner', 'use', 'their', 'voice', 'and', 'vote', 'i', 'have', 'never', 'voted', 'before', 'in', 'my', 'life', 'but', 'that', 'changes', 'next', 'year', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['cuckservative', 'medien', 'calls', 'trump', 'a', 'liberal', 'kike', ',', 'media', 'calls', 'him', 'far', 'right', ',', 'tired', 'of', 'these', 'deceitful', 'cocksuckers', '.'], ['B-B', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['britische', 'regierung', 'says', 'the', 'weiße', 'rasse', 'will', 'kill', 'all', 'other', 'races', 'soon', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['yes', ',', 'he', 'has', 'a', 'right', 'to', 'film', ',', 'but', 'it', \"'s\", 'not', 'worth', 'someone', 'losing', 'a', 'life', 'over', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['the', 'small', 'minority', 'of', 'colossal', 'fuck-ups', 'on', 'video', 'make', 'their', 'way', 'to', 'the', 'news', 'frontpage', 'which', 'gives', 'american', 'police', 'a', 'terrible', 'image', '.'], ['n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['hier', 'sollte', 'mal', 'gesagt', 'werden', ',', 'dass', 'die', 'jährlichen', 'flüchtlingskosten', 'insgesamt', '55', 'milliarden', 'euro', 'betragen', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['ich', 'bin', 'froh', ',', 'dass', 'wir', 'diesen', 'idioten', 'nicht', 'mehr', 'mit', 'unseren', 'steuergeldern', 'bezahlen', 'müssen', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['ich', 'lebe', 'mein', 'life', ',', 'gebe', 'ein', 'scheiß', 'und', 'zeig', ',', 'dass', 'die', 'industrie', 'sich', 'an', 'mir', 'die', 'zähne', 'zerbeißt', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['da', 'will', 'einer', 'unter', 'polizeischutz', 'sein', 'eigentum', 'vom', 'schrott', 'der', 'besetzer', 'säubern', 'lassen', 'und', 'diese', 'werden', 'dann', 'mit', '(', 'sorry', ')', 'scheiße', 'beworfen', '?'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n'])\n",
            "(['i', 'ca', \"n't\", 'believe', 'people', 'can', 'be', 'this', 'fucking', 'retarded', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'B', 'n'])\n",
            "(['it', 'sounds', 'just', 'like', 'justice', 'mixed', 'with', 'weiße', 'tränen', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['schick', 'mir', 'deine', 'wife', 'her', ',', 'mein', 'dick', 'ist', 'steif', ',', 'yeah', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['i', 'would', 'fuck', 'her', 'and', 'cum', 'in', 'her', ',', 'she', \"'s\", 'such', 'a', 'lovely', 'cumslut', '.'], ['n', 'n', 'B-B', 'n', 'n', 'B-B', 'B', 'B', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['dumm', ',', 'dümmer', ',', 'deutschland', '!'], ['B-B', 'n', 'B-B', 'n', 'n', 'n'])\n",
            "(['yeah', 'his', 'last', 'interview', 'certainly', 'was', 'his', 'last', 'big', 'act', 'of', 'bullshitting', 'people', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n'])\n",
            "(['a', 'nicht', 'funktionierende', 'autoritäre', 'regierung', 'will', 'not', 'even', 'work', 'for', 'the', 'weiße', 'konservative', 'most', 'of', 'them', 'are', 'weiß', 'unter', 'bis', 'mittelklasse', 'who', 'are', 'so', 'terrified', 'of', 'becoming', 'like', 'the', 'schlecht', 'arbeitend', 'they', 'see', 'jeden', 'tag', 'a', 'nicht', 'effiziente', 'regierung', 'will', 'not', 'help', 'them', 'there', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['yo', ',', 'ich', 'weiß', 'genau', ',', 'ich', 'bin', 'am', 'freestyln', ',', 'kick', 'die', 'rhymes', ',', 'kay', 'one', ',', 'jam', 'fm', ',', 'ich', 'spitte', 'den', 'shit', 'grade', 'live', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n'])\n",
            "(['und', 'wenn', 'ich', 'abspritz', 'wiegen', 'bitches', 'eine', 'tonne', ',', 'ich', 'bin', 'zu', 'tight', ',', 'kicke', 'den', 'shit', 'von', 'berlin', 'nach', 'kuwait', '.'], ['n', 'n', 'n', 'B-B', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['dumm', 'geboren', 'und', 'nix', 'dazugelernt'], ['B-B', 'n', 'n', 'n', 'n'])\n",
            "(['man', 'kann', 'auch', 'jeden', 'scheiss', 'als', 'soziales', 'ereignis', 'verkaufen', '.'], ['n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['money', 'kommt', 'auf', 'mein', 'paypal', ',', 'rolies', ',', 'bitches', ',', 'diamanten', ',', 'alles', 'andre', 'hab', \"'\", 'ich', 'nie', 'verstanden', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['these', 'fuckers', 'who', 'have', 'done', 'this', 'to', 'our', 'lands', 'must', 'confess', 'that', 'they', 'lied', 'to', 'shitskins', 'and', 'flooded', 'our', 'lands', '.'], ['n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['make', 'amerika', 'friedlich', 'again', 'clean', 'the', 'muzzie', 'filth', 'from', 'our', 'society', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'B', 'n', 'n', 'n', 'n'])\n",
            "(['fick', 'das', 'weiße', 'haus', 'in', 'washington', 'd.c', 'wir', 'kommen', 'nachts', 'im', 'suv', ',', 'wir', 'sind', 'public', 'enemies', '.'], ['B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['of', 'course', 'they', 'are', 'all', 'weiße', 'oberhäupter', 'you', 'idiot', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['doch', 'wir', 'probieren‘s', ',', 'i', 'wonder', 'if', 'heaven', 'got', 'a', 'ghetto', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['dumme', 'nigger-hure', 'thinks', 'the', 'country', 'can', 'function', 'off', 'of', 'innerstädtische', 'arbeitsplätze', 'and', 'people', 'does', 'she', 'even', 'realize', 'who', 'feeds', 'her', '.'], ['B-B', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['er', 'sagte', ':', 'komm', ',', 'recorden', ',', 'zu', 'uns', ',', 'nach', 'berlin', ',', 'kurz', 'vorm', 'untergrund-deal', ',', 'shit', ',', 'ich', 'brauchte', 'wieder', 'geld', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['mit', 'verlaub', 'herr', 'bundestagspräsident', ',', 'sie', 'sind', 'ein', 'arsch', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['my', 'bester', 'freund', 'constantly', 'whines', 'about', 'how', 'i', 'got', 'the', 'ghetto', 'booty', 'and', 'the', 'weiße', 'haut', 'and', 'somehow', 'she', 'got', 'the', 'weißer', 'arsch', 'and', 'the', 'dunkle', 'haut', 'we', 'are', 'an', 'amüsantes', 'paar', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['yes', ',', 'motherfucker', ',', 'ich', 'zog', 'nach', 'berlin', ',', 'verließ', 'gladbach', ',', 'um', \"'\", 'ne', 'neue', 'wohnung', 'zu', 'beziehen', '.'], ['n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['decoding', 'that', 'through', 'their', 'smart-ass', 'answer', '.'], ['n', 'n', 'n', 'n', 'B-B', 'n', 'n'])\n",
            "(['omfg', ',', 'i', \"'m\", 'so', 'tired', 'of', 'myself', 'right', 'now', '...', 'that', \"'s\", 'so', 'stupid', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['damn', 'son', ',', 'how', 'many', 'flavors', 'of', 'stupid', 'are', 'you', '?'], ['B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n'])\n",
            "(['heute', 'noch', 'besoffen', ',', 'denn', 'ich', 'war', 'gestern', 'im', 'matrix', 'ich', 'kick', 'den', 'shit', 'von', 'wannsee', 'bis', 'nach', 'steglitz', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['senior', 'eu', 'beamter', 'sagte', 'it', 'was', 'part', 'of', 'poland', 'push', 'towards', 'selbst-ghettoisierung', 'is', 'not', 'that', 'rich', 'another', 'example', 'of', 'liberale', 'globalistische', 'übertragung', 'the', 'only', 'ghetto', 'in', 'the', 'eu', 'are', 'the', 'muslim', 'schwein', 'schwanzsauger', 'ghettos', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'B-B', 'n', 'n'])\n",
            "(['inhaltlich', 'hat', 'sie', 'natürlich', 'recht', '.'], ['n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['it', \"'s\", 'not', 'so', 'much', 'defending', 'a-rod', 'as', 'it', 'is', 'seeing', 'all', 'of', 'baseball', 'go', 'apeshit', 'on', 'the', 'guy', 'but', 'pretty', 'much', 'selectively', 'brush', 'off', 'other', 'people', 'using', 'and', 'doing', 'the', 'same', 'damn', 'thing', ',', 'or', 'worse', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['wenn', 'ich', 'jetzt', 'mal', 'eben', 'um', '5,7', 'millionen', 'euro', 'reicher', 'geworden', 'bin', 'würde', 'ich', 'auch', 'das', 'grinsen', 'nicht', 'mehr', 'aus', 'dem', 'gesicht', 'bekommen', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['ja', 'und', 'zweitens', ':', 'sonny', 'bounct', 'den', 'beat', 'und', 'ich', 'kann', 'rhymen', '!'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['i', 'like', 'how', 'the', 'white', 'women', 'noped', 'the', 'fuck', 'out', 'of', 'there', 'once', 'the', 'niggers', 'started', 'beating', 'on', 'each', 'other', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['das', 'ist', 'wie', 'german', 'dream', ':', 'da', 'wird', 'armani', 'dabei', 'sein', 'und', 'ich', 'kauf', \"'\", 'die', 'gesamte', 'frühlingskollektion', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['that', 'is', 'some', 'schwarzes', 'leben', 'matter', 'dumme', 'ärsche', 'disrupting', 'a', 'college', 'classroom', 'by', 'jumping', 'on', 'the', 'desks', 'and', 'chanting', 'some', 'retarded', 'tripe', 'about', 'racism', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n'])\n",
            "(['i', 'do', \"n't\", 'think', 'you', 'asked', 'a', 'question', ',', 'as', 'you', 'know', 'the', 'answer', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['rapper', 'laufen', 'noch', 'zu', 'gucci', ',', 'ich', 'trag', 'custom-made', 'brioni', ',', 'du', 'no-name', ',', 'ich', 'bin', 'auf', 'der', 'street', 'the', 'one', 'and', 'only', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['the', 'liberal', 'behinderte', 'arschlöcher', 'in', 'the', 'canadian', 'government', 'do', 'not', 'like', 'it', 'when', 'anyone', 'speaks', 'the', 'truth', '.'], ['n', 'n', 'B-B', 'B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['blowjobs', 'are', 'a', 'better', 'motivator', 'for', 'me', 'than', 'money', 'is', '.'], ['B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['why', 'do', 'normal', 'zivilisierte', 'länder', 'want', 'to', 'become', 'retarded', 'islamic', 'nations', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n'])\n",
            "(['why', 'bother', 'having', 'a', 'church', 'with', 'this', 'crap', 'and', 'islam', 'next', 'to', 'gay', 'scheiße', '?'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['offenbach', 'city', ',', 'jetzt', 'kackt', 'der', 'rest', 'ab', ',', 'drecksratten', 'lästern', 'weil', 'ich', 'cash', 'mach', '.'], ['n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['nehm', 'mir', 'nur', 'zeit', 'für', 'die', 'main-bitch', ',', 'doch', 'geh', 'nicht', 'ins', 'kino', ',', 'bin', 'famous', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['biologische', 'männer', 'who', 'regard', 'themselves', 'as', 'women', 'are', 'being', 'invited', 'for', 'zervixabstrichtests', 'even', 'though', 'it', 'is', 'impossible', 'for', 'them', 'to', 'have', 'a', 'cervix', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['brainwash', ',', 'optik', 'scientology', ',', 'wir', 'ficken', 'dein', 'kopf', ',', 'optik', 'scientology', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['und', 'so', 'einer', 'dumpfbacke', 'wird', 'honig', 'wohin', 'geschmiert', ',', 'damit', 'er', 'in', 'ost-deutschland', 'eine', 'fabrik', 'baut', '?'], ['n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['kein', 'mc', 'kann', 'mich', 'nachmachen', ',', 'guck', ',', '\"', 'it', 'ai', \"n't\", 'hard', 'to', 'tell', '\"', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['one', 'of', 'you', 'faggots', 'did', 'not', 'like', 'my', 'jüdische', 'unterstützung', 'i', 'want', 'you', 'to', 'call', 'me', 'out', 'you', 'pussy', 'you', 'a', 'man', 'or', 'a', 'mouse', 'i', 'will', 'take', 'a', 'wirklicher', 'mann', 'i', 'will', 'not', 'take', 'a', 'mouse', 'i', 'will', 'load', 'my', 'gun', 'you', 'are', 'sounding', 'like', 'a', 'schwuchtel-muzzie', '.'], ['n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['now', ',', 'my', 'issue', ',', 'is', 'staying', 'the', 'full', '8', 'hours', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['me', 'too', ',', 'i', 'live', 'by', 'the', 'bow', 'and', 'during', 'the', 'summer', 'fuckloads', 'of', 'geese', 'strut', 'around', 'here', 'shitting', 'all', 'over', 'everything', ',', 'they', 'are', 'really', 'more', 'of', 'a', 'nuisance', 'than', 'anything', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['highlevel-ignoranz', ',', 'hater', 'labern', 'weiter', 'bullshit', '.'], ['n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['scheiß', 'auf', 'fame', ',', 'auf', 'das', 'cash', 'und', 'die', 'bitches', '.'], ['B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['bender', 'is', 'going', 'to', 'start', 'his', 'own', 'team', ',', 'with', 'blackjack', 'and', 'hookers', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['instant', 'lösung', 'neu', 'einsetzen', 'the', 'us', 'military', 'from', 'protecting', 'kikes', 'and', 'arabs', 'in', 'the', 'mittlerer', 'osten', 'to', 'the', 'border', 'with', 'mexico', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['wer', 'hier', 'der', 'idiot', 'ist', 'sagt', 'schon', 'ihr', 'name', 'aus', '...', 'gute', 'heimreise', '!'], ['n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['fuck', ',', 'this', 'sub', 'is', 'a', 'parody', 'of', 'itself', 'sometimes', '.'], ['B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['verwöhnte', 'bonzen-slut', ',', 'auf', 'einmal', 'kommen', 'sie', 'alle', 'wieder', ',', 'sie', 'haten', ',', 'weil', 'ich', 'jetzt', 'cash', 'mit', 'rapmusik', 'verdiene', '.'], ['n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['sie', 'hat', 'flexibility', ',', 'wir', 'sind', 'public', 'enemy', ',', 'ihr', 'police', 'academy', ',', 'yeah', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['wow', 'i', 'love', 'this', 'erstgenannter', 'inhalt', 'of', 'you', 'calling', 'people', 'faggots', 'all', 'day', 'it', 'a', 'klares', 'zeichen', 'of', 'intellectual', 'dominance', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['baby', ',', 'dein', 'arsch', ',', 'er', 'ist', 'nice', 'in', 'den', 'leggings', ',', 'warum', 'chillst', 'du', 'mit', 'den', 'faggots', '?'], ['n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['miss', 'america', 'shall', 'embrace', 'beer', 'for', 'beer', 'makes', 'fettfrauen', 'look', 'beautiful', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n'])\n",
            "(['these', 'bitches', 'have', 'no', 'shame', 'they', 'are', 'so', 'starved', 'for', 'affection', 'they', 'go', 'with', 'some', 'stinkender', 'ghetto-niggerh-affe', '.'], ['n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'B', 'n'])\n",
            "(['blabla', 'du', 'scheiß-faker', 'smile', 'now', ',', 'cry', 'later', ',', 'mittelfinger', 'hoch', '.'], ['n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['ich', 'bin', 'mir', 'sicher', ',', 'kaum', 'einer', 'der', 'weißhäutigen', 'kommentatoren', 'im', 'forum', 'möchte', 'als', '\"', 'kalkarsch', '\"', 'angesprochen', 'oder', 'bezeichnet', 'werden', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['ich', 'fänd', \"'s\", 'toll', ',', 'wenn', 'sich', 'die', 'pc-bewegten', 'als', 'vollpfosten', 'verkleiden', 'würden', ';', 'das', 'passt', 'dann', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['vereinbarte', 'öffentliche', 'beschämung', 'is', 'usually', 'enough', 'to', 'keep', 'faggots', 'in', 'the', 'closet', 'anyway', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['gouverneurin', 'mcauliffe', 'declared', 'a', 'state', 'of', 'emergency', 'after', 'sucking', 'nigger', 'cocks', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'B', 'B', 'n'])\n",
            "(['so', 'dieser', 'unberechenbare', 'dreckskerl', 'nicht', 'die', 'verfassung', 'noch', 'ändert', ',', 'ist', 'er', 'spätestens', 'nach', 'der', 'zweiten', 'amtszeit', 'von', 'der', 'politischen', 'bildfläche', 'verschwunden', '.'], ['n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['das', 'war', 'doch', 'bestimmt', 'dieser', 'loser', 'hecking', 'schuld', '....', 'der', 'kann', 'ja', 'aber', 'auch', 'gar', 'nix', ',', 'dieser', 'versager', '.'], ['n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['bros', 'before', 'hoes', ',', 'unless', 'said', 'hoe', 'is', 'really', 'cute', 'and', 'not', 'a', 'total', 'bitch', ',', 'in', 'which', 'case', ',', 'divide', 'your', 'attention', 'between', 'your', 'bros', 'and', 'your', 'hoes', 'almost', 'evenly', '.'], ['n', 'n', 'B-B', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n'])\n",
            "(['ist', 'auch', 'besser', 'so', ',', 'weil', 'ein', 'punch', 'dich', 'crack-bitch', 'mit', 'der', 'einschlagskraft', 'einer', 'salve', 'aus', \"'\", 'ner', 'pumpgun', 'wegfickt', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['the', 'sandnigger', 'deserve', 'the', 'same', '.'], ['n', 'B-B', 'n', 'n', 'n', 'n'])\n",
            "(['wir', 'werden', 'von', 'daherschwätzenden', 'volldeppen', 'regiert', 'und', 'die', 'medien', 'spenden', 'applaus', '.'], ['n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['the', 'abschaum-herrscher', 'of', 'the', 'westliche', 'welt', 'are', 'in', 'trouble', 'and', 'we', 'are', 'at', 'the', 'precipice', 'of', 'either', 'they', '.'], ['n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['i', 'think', 'you', 'need', 'handschellen', 'whore', '.'], ['n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['wo', 'sie', 'recht', 'haben', ',', 'besteht', 'wenigstens', 'nicht', 'mehr', 'die', 'gefahr', ',', 'dass', 'mir', 'der', 'depp', 'mit', 'dem', 'käppi', 'von', 'nebenan', 'den', 'autolack', 'mit', 'einer', 'fontäne', 'abfackelt', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['hör', 'mal', ',', 'denn', 'mein', 'erster', 'text', 'ging', 'ungefähr', 'so', 'ah', 'yeah', ',', 'since', '1983', 'i', \"'m\", 'the', 'prince', 'of', 'my', 'thug', 'family', 'but', 'especially', 'of', 'my', 'motherfucking', 'hood', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n'])\n",
            "(['diese', 'spinner', 'sind', 'hohl', ',', 'denken', ':', 'let', \"'s\", 'get', 'it', 'on', '.'], ['n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['stumptown', 'is', 'a', 'scheiß-show', 'the', 'writers', 'are', 'retarded', 'the', 'story', 'is', 'boring', 'it', 'is', 'a', 'total', 'waste', 'of', 'its', 'fantastic', 'cast', '.'], ['n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['ich', 'kauf', 'der', 'bitch', 'einen', 'gucci', 'slip', ',', 'denn', 'sie', 'ist', '′ne', 'nice', 'groupie', 'chick', ',', 'ihr', 'booty', 'thick', '.'], ['n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'B', 'n', 'n', 'B-B', 'n', 'n'])\n",
            "(['you', 'are', 'ziemlich', 'behindert', 'and', 'english', 'clearly', 'is', 'not', 'your', 'first', 'language', 'try', 'punctuation', 'next', 'time', 'it', 'really', 'helps', '.'], ['n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['i', 'know', 'in', 'my', 'experiences', 'on', 'it', 'i', \"'ve\", 'only', 'rarely', 'encountered', 'other', 'women', '!'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['idk', 'gpaw', 'if', 'we', 'have', 'to', 'suffer', 'the', 'presence', 'of', 'scheiße', '!'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['und', 'ich', 'weiß', 'ganz', 'genau', ',', 'verdammt', ',', 'ich', 'spitte', 'jeden', 'scheiß', 'ich', 'rappe', 'niemals', 'über', 'bling', 'und', 'niemals', 'über', 'schlampen', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['he', 'was', 'an', 'zuwanderer', 'amerika', 'can', 'be', 'proud', 'of', 'and', 'i', 'wonder', 'what', 'inventions', 'the', 'muslimische', 'flüchtlinge', 'bring', 'oh', 'ja', ',', 'das', 'ist', 'es', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['ich', 'alleine', 'pay', 'für', \"'\", 'ne', 'ganze', 'kanzlei', ',', 'die', 'richterin', 'ist', 'mal', 'wieder', 'so', 'ein', 'mannsweib', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['ich', 'spitte', 'den', 'shit', 'grade', 'live', 'und', 'ich', 'weiß', 'ganz', 'genau', ',', 'mann', ',', 'ich', 'bin', 'anders', 'drauf', '.'], ['n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['denn', 'ihr', 'wisst', 'es', ',', 'ich', 'hab', 'diesen', 'brand', 'new', 'flava', 'in', 'ya', 'ear', ',', 'yeah', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['i', \"'m\", 'suprised', 'israel', 'does', \"n't\", 'have', 'more', 'olympic', 'gold', 'medals', 'since', 'they', 'love', 'that', 'shit', 'so', 'much', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n'])\n",
            "(['and', 'if', 'you', 'do', \"n't\", 'know', ',', 'now', 'you', 'know', ',', 'spinner', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['ich', 'spit', 'ein', 'vielfaches', 'fresher', 'als', 'jedes', 'kind', 'das', 'rappt', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['at', 'this', 'point', ',', 'he', 'shuddered', 'slightly', ',', 'and', 'his', 'balance', 'seemed', 'to', 'wane', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['gib', 'mir', 'nen', 'grund', ',', 'du', 'hund', 'und', 'ich', 'bums', 'dich', 'in', 'den', 'mund', 'wichser', ',', 'ich', 'hab', \"'s\", 'euch', 'gesagt', ',', 'komm', 'back', 'in', 'das', 'game', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'B-B', 'B', 'B', 'B', 'B', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['i', 'wish', 'all', 'niggers', 'stop', 'wearing', 'these', 'fettarsch', 'fanny', 'packs', 'i', 'hate', 'them', '.'], ['n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'B-B', 'B-B', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['you', 'can', 'test', 'this', 'theory', 'yourself', 'by', 'going', 'to', 'the', 'ghetto', 'and', 'asking', 'schwarze', 'menschen', 'to', 'suck', 'your', 'dick', 'and', 'seeing', 'what', 'their', 'reaction', 'is', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'B', 'B', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['der', 'friedhof', 'hamburg-ohlsdorf', 'war', 'schon', 'immer', 'so', 'ein', 'park', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['auf', 'der', 'jagd', 'nach', 'lügnern', 'und', 'ihren', 'fake', 'records', 'ich', 'reiß', \"'\", 'dich', 'in', 'fetzen', ',', 'weis', 'dich', 'in', 'deine', 'grenzen', ',', 'idiot', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['durchschnittliche', 'iqs', 'and', 'overall', 'wirtschaftlicher', 'erfolg', 'of', 'races', 'will', 'tell', 'you', 'jews', 'and', 'asians', 'rank', 'well', 'above', 'whites', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['the', 'only', 'good', 'muzzie', 'is', 'a', 'toter', 'muzzie', 'make', 'them', 'all', 'good', 'muzzis', 'mohammed', 'was', 'a', 'schwanzsaugen', 'pädophile', 'and', 'a', 'piece', 'of', 'shit', 'just', 'like', 'every', 'raghead', '.'], ['n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'B-B', 'B', 'B', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['and', 'there', 'is', 'absolutely', 'no', 'way', 'to', 'tell', 'that', 'it', 'was', 'a', 'chimp', 'tearing', 'off', 'her', 'face', 'based', 'on', 'the', 'background', 'noise', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['would', 'much', 'rather', 'they', 'were', 'raised', 'by', 'a', 'bunch', 'of', 'faggots', 'than', 'by', 'the', 'animals', 'that', 'birthed', 'them', 'or', 'god', 'forbid', 'these', 'disgusting', 'weiß', 'christian', 'cucks', 'ya', 'know', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'B', 'B', 'B', 'n', 'n', 'n'])\n",
            "(['ist', 'mir', 'schon', 'zu', 'blöd', ',', 'mich', 'zu', 'äussern', ',', 'ich', 'guck', 'den', 'scheiß', 'eh', 'nicht', '.'], ['n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n'])\n",
            "(['mein', 'dick', 'ist', 'so', 'groß', ',', 'bitches', 'sagen', 'mach', 'mal', 'halblang', '.'], ['n', 'B-B', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['trump', 'faces', 'what', 'fathers', 'fear', 'his', 'tochter', 'heiratet', 'a', 'nigger', 'but', 'this', 'is', 'worse', 'the', 'fotze', 'verheiratet', 'a', 'sandnigger', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'B-B', 'n'])\n",
            "(['can', 'not', 'believe', 'that', 'verdammte', 'schlampe', 'hit', 'my', 'car', '.'], ['n', 'n', 'n', 'n', 'B-B', 'B', 'n', 'n', 'n', 'n'])\n",
            "(['was', 'für', 'fast-life', '?', 'deutscher', 'rap', 'ist', 'stop-and-go', ',', 'meine', 'attitude', 'ist', 'irgendwann', 'für', 'sie', 'zu', 'rock-n-roll', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['how', 'dare', 'trump', 'say', 'shithole', 'he', 'calling', 'those', 'ausländische', 'immigranten', 'scheiße', '.'], ['n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n'])\n",
            "(['ich', 'bin', 'wieder', 'back', 'im', 'game', 'bitch', 'drück', 'play', 'ich', 'hab', 'euch', 'gewarnt', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['jetzt', 'ist', 'krieg', ',', 'fick', 'dein', 'liebeslied', ',', 'sonny', 'bounced', 'den', 'deepen', 'beat', ',', 'komm', '.'], ['n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['so', 'glad', 'the', 'leader', 'of', 'the', 'hillbilly', 'mafia', 'is', 'not', 'in', 'the', 'weißes', 'haus', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['i', 'would', 'like', 'to', 'volunteer', 'a', 'rafting', 'service', 'for', 'wiedereingliederung', 'von', 'einwanderern', 'and', 'their', 'kids', 'they', 'can', 'travel', 'kostenlos', 'zusammen', 'across', 'the', 'rio', 'grande', 'or', 'tijuana', 'rivers', 'to', 'mexico', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['wen', 'interessiert', 'schon', 'so', 'etwas', '.'], ['n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['wenn', 'du', 'nicht', 'vorsichtig', 'bist', ',', 'macht', 'jeder', 'auf', 'loyal', 'und', 'aufrecht', ',', 'um', 'dich', 'dann', 'zu', 'ficken', ',', 'die', 'streets', 'sind', 'voll', 'mit', 'schlangen', 'wie', 'das', 'outback', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['all', 'of', 'ya', 'can', 'suck', 'my', 'dick', 'if', 'it', 'was', 'ihr', 'freund', 'who', 'got', 'raped', 'and', 'ihr', 'freund', 'who', 'got', 'assaulted', 'you', 'would', 'not', 'be', 'sitting', 'there', 'like', 'what', 'about', 'his', 'side', 'your', 'fuck', 'you', 'all', '.'], ['n', 'n', 'n', 'n', 'B-B', 'B', 'B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'B', 'n', 'n'])\n",
            "(['sollte', 'fortuna', 'absteigen', ',', 'werden', 'schäfer', 'und', 'ernst', 'die', 'deppen', 'sein', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n'])\n",
            "(['doch', 'sag', 'mal', 'nix', ',', 'ich', 'kombinier', 'die', 'lines', 'wie', 'sudoku', 'und', 'keep', 'them', 'shook', 'crews', 'runnin', 'like', 'they', 'supposed', 'to', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n'])\n",
            "(['i', 'will', 'not', 'stop', 'them', 'either', 'dummer', 'arsch', 'hug', 'a', 'muzzie', '.'], ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'B-B', 'n'])\n"
          ]
        }
      ],
      "source": [
        "csv_file_path = 'Labeled_dataset_cdd.csv'\n",
        "\n",
        "sentences = {}\n",
        "with open(csv_file_path, 'r') as file:\n",
        "    csv_reader = csv.reader(file)\n",
        "    next(csv_reader)\n",
        "    for row in csv_reader:\n",
        "        sentence_id, token, label = row\n",
        "        if sentence_id not in sentences:\n",
        "            sentences[sentence_id] = {'tokens': [], 'labels': []}\n",
        "        sentences[sentence_id]['tokens'].append(token)\n",
        "        sentences[sentence_id]['labels'].append(label)\n",
        "\n",
        "result_cdd = []\n",
        "for sentence_id, data in sentences.items():\n",
        "    words = data['tokens']\n",
        "    labels = data['labels']\n",
        "    result_cdd.append((words, labels))\n",
        "\n",
        "for sentence in result_cdd:\n",
        "    print(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFMGKpeQtJmj",
        "outputId": "dbd08288-e9ca-4727-fc44-e83afc1f62a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CDD set length: 150\n"
          ]
        }
      ],
      "source": [
        "cdd_data = result_cdd\n",
        "print(f\"CDD set length: {len(cdd_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyFAr0RntRmO",
        "outputId": "64fe1654-3e1e-42df-fbab-94c401006ee7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   terms\n",
            "0                 stupid\n",
            "1              subhumans\n",
            "2                  sluts\n",
            "3              sub-human\n",
            "4                  filth\n",
            "..                   ...\n",
            "144             fagtards\n",
            "145            behindert\n",
            "146  ghetto-scheißlöcher\n",
            "147                kackt\n",
            "148              apeshit\n",
            "\n",
            "[149 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "gold_set_for_cdd = set(word for (words, labels) in cdd_data for word, label in zip(words, labels) if label == 'B-B' or label == 'B')\n",
        "\n",
        "df_gold_cdd = pd.DataFrame({'terms': list(gold_set_for_cdd)})\n",
        "print(df_gold_cdd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "0d2DFSWttYPA"
      },
      "outputs": [],
      "source": [
        "cdd_tags=[tup[1] for tup in cdd_data]\n",
        "cdd_texts=[tup[0] for tup in cdd_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "DSOQy9X2tgM1"
      },
      "outputs": [],
      "source": [
        "cdd_input_and_labels = tokenize_and_align_labels(cdd_texts, cdd_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "lHhrfmQ3trMX"
      },
      "outputs": [],
      "source": [
        "cdd_dataset = Dataset(cdd_input_and_labels, cdd_input_and_labels[\"labels\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "qqJT4aEQttjX"
      },
      "outputs": [],
      "source": [
        "def compute_metrics_cdd(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    extracted_terms = extract_terms(true_predictions, cdd_texts)\n",
        "    extracted_terms = set([item.lower() for item in extracted_terms])\n",
        "\n",
        "    gold_set = set(word for (words, labels) in cdd_data for word, label in zip(words, labels) if label == 'B-B' or label == 'B')\n",
        "\n",
        "    true_pos = extracted_terms.intersection(gold_set)\n",
        "    recall = len(true_pos) / len(gold_set) if len(gold_set) > 0 else 0\n",
        "    precision = len(true_pos) / len(extracted_terms) if len(extracted_terms) > 0 else 0\n",
        "\n",
        "    return {\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9W7_cULuCI7"
      },
      "source": [
        "# DFT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "_-lLFjIRuDll"
      },
      "outputs": [],
      "source": [
        "model = XLMRobertaForTokenClassification.from_pretrained(\"/content/best_model_dft\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "W_D0JGlwuGzp"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    per_device_eval_batch_size=16,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    do_eval=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "ytafiKXfuIzD"
      },
      "outputs": [],
      "source": [
        "trainer_dft = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        eval_dataset=cdd_dataset,\n",
        "        compute_metrics=compute_metrics_cdd,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "an7kiSqSuMjD",
        "outputId": "ba380c6b-2987-4bac-d0a2-a1b67edbfefb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluation results: {'eval_loss': 0.2319251000881195, 'eval_model_preparation_time': 0.0034, 'eval_precision': 0.7142857142857143, 'eval_recall': 0.6040268456375839, 'eval_f1': 0.6545454545454547, 'eval_runtime': 0.6563, 'eval_samples_per_second': 228.554, 'eval_steps_per_second': 15.237}\n"
          ]
        }
      ],
      "source": [
        "eval_results_dft = trainer_dft.evaluate()\n",
        "print(f\"evaluation results: {eval_results_dft}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "UMtn5pF1uOqI",
        "outputId": "86aee41e-c092-4ac9-e58b-05ec1dc9b439"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "True: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "Predicted: ['n', 'n', 'n', 'B-B', 'n']\n",
            "True: ['n', 'n', 'n', 'B-B', 'n']\n",
            "Predicted: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "True: ['n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "Predicted: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "True: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "Predicted: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n']\n",
            "True: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'B-B', 'n', 'n']\n"
          ]
        }
      ],
      "source": [
        "dft_predictions, dft_labels, dft_metrics = trainer_dft.predict(cdd_dataset)\n",
        "\n",
        "dft_predictions = np.argmax(dft_predictions, axis=2)\n",
        "\n",
        "true_dft_predictions = [\n",
        "    [label_list[p] for (p, l) in zip(dft_prediction, dft_label) if l != -100]\n",
        "    for dft_prediction, dft_label in zip(dft_predictions, dft_labels)\n",
        "]\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"Predicted: {true_dft_predictions[i]}\")\n",
        "    print(f\"True: {[label_list[l] for l in dft_labels[i] if l != -100]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "dESfYAosuY35"
      },
      "outputs": [],
      "source": [
        "dft_extracted_terms = extract_terms(true_dft_predictions, cdd_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CS5JeI0WuanE",
        "outputId": "48260b57-8c87-4890-8bd4-db212a00ac24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'stupid', 'ärsche', 'deppen', 'motherfucker', 'toter', 'schwein', 'nuttensohn', 'gucci', 'sandniggers', 'cumslut', 'hater', 'versace-nutten', 'shook', 'armani', 'freestyln', 'scheiß-show', 'amerikaner', 'chick', 'schwuchtel-muzzie', 'flava', 'kaukasier', 'scheiß-faker', 'thick', 'dumm', 'chimp', 'fettarsch', 'schwanzsaugen', 'klugscheisser', 'abspritz', 'arsch', 'booty', 'raghead', 'kopf', 'recorden', 'blöd', 'scheiss', 'scheiße', 'spic', 'niggers', 'tripe', 'mistkind', 'ficken', 'mohr', 'dumme', 'idioten', 'scheißhaut', 'fotze', 'gangster', 'crack-bitch', 'brioni', 'vollpfosten', 'bonzen-slut', 'depp', 'muzzie', 'volldeppen', 'whore', 'trottel', 'pimmel', 'stinkender', 'groupie', 'schlampe', 'idiot', 'handschellen', 'shithole', 'fresher', 'käppi', 'bitches', 'zähne', 'geese', 'kike', 'verdammte', 'bitch', 'spinner', 'mannsweib', 'drecksratten', 'kalkarsch', 'behinderte', 'scheiß', 'faggot', 'bounct', 'rolies', 'neger', 'bullshitting', 'bender', 'kikes', 'ghetto-niggerh-affe', 'dreckskerl', 'daherschwätzenden', 'pussy', 'schlampen', 'wack', 'chink', 'dumpfbacke', 'abschaum', 'shitskins', 'hecking', 'verdammt', 'scheißegal', 'rappe', 'broad', 'wildschweine', 'tochter', 'zuwanderer', 'muzzis', 'wichser', 'dummkopf-schlampe', 'schwanzsauger', 'nuts', 'arschlöcher', 'dummer', 'versager', 'dumb', 'fick', 'nigger', 'sandnigger', 'dümmer', 'cucks', 'fanny', 'bling', 'fetzen', 'nigger-hure', 'punch', 'fagtards', 'kackt', 'krieg', 'apeshit'}\n"
          ]
        }
      ],
      "source": [
        "print(dft_extracted_terms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpPxZJiKud8R",
        "outputId": "7689849c-b765-4d15-dee3-5fb23e1ea895"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intersection 90\n",
            "Gold 149\n",
            "Extracted 126\n",
            "Recall: 0.6040268456375839\n",
            "Precision: 0.7142857142857143\n",
            "F1: 0.6545454545454547\n"
          ]
        }
      ],
      "source": [
        "computeTermEvalMetrics(dft_extracted_terms, gold_set_for_cdd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HIYtHgVvUGx"
      },
      "source": [
        "# DEFT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "uRlGFT8dvToC"
      },
      "outputs": [],
      "source": [
        "model = XLMRobertaForTokenClassification.from_pretrained(\"/content/best_model_deft\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "yTJdQzwEvXqE"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    per_device_eval_batch_size=16,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    do_eval=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "RB0C5tl1vZmW"
      },
      "outputs": [],
      "source": [
        "trainer_deft = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        eval_dataset=cdd_dataset,\n",
        "        compute_metrics=compute_metrics_cdd,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "z0mjE1zkvdCZ",
        "outputId": "19b33664-e518-449b-b38b-abb32f5fae33"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluation results: {'eval_loss': 0.13920938968658447, 'eval_model_preparation_time': 0.003, 'eval_precision': 0.8702290076335878, 'eval_recall': 0.7651006711409396, 'eval_f1': 0.8142857142857143, 'eval_runtime': 0.6433, 'eval_samples_per_second': 233.157, 'eval_steps_per_second': 15.544}\n"
          ]
        }
      ],
      "source": [
        "eval_results_deft = trainer_deft.evaluate()\n",
        "print(f\"evaluation results: {eval_results_deft}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "i-S9oi9qvfU-",
        "outputId": "708a83a6-f3a4-4d9e-a573-8d85ebb04285"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "True: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "Predicted: ['n', 'n', 'n', 'B-B', 'n']\n",
            "True: ['n', 'n', 'n', 'B-B', 'n']\n",
            "Predicted: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "True: ['n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "Predicted: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "True: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "Predicted: ['n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'B-B', 'n', 'B-B', 'n', 'n']\n",
            "True: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'B-B', 'n', 'n']\n"
          ]
        }
      ],
      "source": [
        "deft_predictions, deft_labels, deft_metrics = trainer_deft.predict(cdd_dataset)\n",
        "\n",
        "deft_predictions = np.argmax(deft_predictions, axis=2)\n",
        "\n",
        "true_deft_predictions = [\n",
        "    [label_list[p] for (p, l) in zip(deft_prediction, deft_label) if l != -100]\n",
        "    for deft_prediction, deft_label in zip(deft_predictions, deft_labels)\n",
        "]\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"Predicted: {true_deft_predictions[i]}\")\n",
        "    print(f\"True: {[label_list[l] for l in deft_labels[i] if l != -100]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "lFQ00egmvl9g"
      },
      "outputs": [],
      "source": [
        "deft_extracted_terms = extract_terms(true_deft_predictions, cdd_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zk3YU6XUvooT",
        "outputId": "6fb16557-f0e2-4091-ff59-cbe5181cac6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'stupid', 'sluts', 'filth', 'deppen', 'hillbilly', 'motherfucker', 'schwein', 'shitting', 'damn', 'nuttensohn', 'cumslut', 'versace-nutten', 'dick', 'armani', 'freestyln', 'crap', 'scheiß-show', 'chick', 'cum', 'nix', 'schwuchtel-muzzie', 'fuck-ups', 'scheiß-faker', 'thick', 'dumm', 'spitte', 'fettarsch', 'chimp', 'schwanzsaugen', 'klugscheisser', 'abspritz', 'arsch', 'booty', 'of', 'blöd', 'scheiss', 'retarded', 'scheiße', 'blowjob', 'spic', 'niggers', 'piece', 'mistkind', 'ficken', 'fuckers', 'dumme', 'idioten', 'scheißhaut', 'fotze', 'crack-bitch', 'bums', 'vollpfosten', 'bonzen-slut', 'depp', 'fast-life', 'smart-ass', 'volldeppen', 'faggots', 'whore', 'trottel', 'abschaum-herrscher', 'groupie', 'schlampe', 'idiot', 'slut', 'hookers', 'handschellen', 'shithole', 'käppi', 'blowjobs', 'son', 'fuck', 'bitches', 'kike', 'verdammte', 'bitch', 'spinner', 'mannsweib', 'fucking', 'drecksratten', 'kalkarsch', 'behinderte', 'thug', 'cocksuckers', 'scheiß', 'faggot', 'neger', 'fettfrauen', 'bullshitting', 'fuckloads', 'kikes', 'dreckskerl', 'dna', 'pussy', 'cocks', 'schlampen', 'chink', 'dumpfbacke', 'abschaum', 'shitskins', 'hecking', 'verdammt', 'schwuchteln', 'scheißegal', 'wichser', 'dummkopf-schlampe', 'schwanzsauger', 'nuts', 'arschlöcher', 'dummer', 'bullshit', 'versager', 'dumb', 'faggotry', 'hug', 'motherfucking', 'fick', 'nigger', 'sandnigger', 'dümmer', 'hoes', 'hohl', 'cucks', 'fanny', 'dry', 'fetzen', 'nigger-hure', 'shit', 'fagtards', 'kackt', 'apeshit'}\n"
          ]
        }
      ],
      "source": [
        "print(deft_extracted_terms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLZ2sOFavpJH",
        "outputId": "1d387556-0482-48f8-ee78-0506d82a9bd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intersection 114\n",
            "Gold 149\n",
            "Extracted 131\n",
            "Recall: 0.7651006711409396\n",
            "Precision: 0.8702290076335878\n",
            "F1: 0.8142857142857143\n"
          ]
        }
      ],
      "source": [
        "computeTermEvalMetrics(deft_extracted_terms, gold_set_for_cdd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp3t0UisC4s5"
      },
      "source": [
        "# CMM\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "A_1WhRhmDF72"
      },
      "outputs": [],
      "source": [
        "model = XLMRobertaForTokenClassification.from_pretrained(\"/content/best_model_cmm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "sScYJvwtDM-E"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    per_device_eval_batch_size=16,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    do_eval=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "2VZGbi9yDNbg"
      },
      "outputs": [],
      "source": [
        "trainer_cmm = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        eval_dataset=cdd_dataset,\n",
        "        compute_metrics=compute_metrics_cdd,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "cFVB25uzDUGK",
        "outputId": "03083813-b1dd-47d6-ba99-e478472c5b12"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluation results: {'eval_loss': 0.22946569323539734, 'eval_model_preparation_time': 0.0029, 'eval_precision': 0.6854838709677419, 'eval_recall': 0.5704697986577181, 'eval_f1': 0.6227106227106227, 'eval_runtime': 0.6398, 'eval_samples_per_second': 234.453, 'eval_steps_per_second': 15.63}\n"
          ]
        }
      ],
      "source": [
        "eval_results_cmm = trainer_cmm.evaluate()\n",
        "print(f\"evaluation results: {eval_results_cmm}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "RNf0SlWHDYdp",
        "outputId": "88c0cd7f-2501-4684-a737-c1987b3cc06c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "True: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "Predicted: ['n', 'n', 'n', 'n', 'n']\n",
            "True: ['n', 'n', 'n', 'B-B', 'n']\n",
            "Predicted: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "True: ['n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "Predicted: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "True: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n', 'n', 'n', 'n']\n",
            "Predicted: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'n', 'n', 'n']\n",
            "True: ['n', 'n', 'n', 'n', 'n', 'n', 'n', 'B-B', 'n', 'B-B', 'n', 'n']\n"
          ]
        }
      ],
      "source": [
        "cmm_predictions, cmm_labels, cmm_metrics = trainer_cmm.predict(cdd_dataset)\n",
        "\n",
        "cmm_predictions = np.argmax(cmm_predictions, axis=2)\n",
        "\n",
        "true_cmm_predictions = [\n",
        "    [label_list[p] for (p, l) in zip(cmm_prediction, cmm_label) if l != -100]\n",
        "    for cmm_prediction, cmm_label in zip(cmm_predictions, cmm_labels)\n",
        "]\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"Predicted: {true_cmm_predictions[i]}\")\n",
        "    print(f\"True: {[label_list[l] for l in cmm_labels[i] if l != -100]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "90qnM8X0DmF-"
      },
      "outputs": [],
      "source": [
        "cmm_extracted_terms = extract_terms(true_cmm_predictions, cdd_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_gsVKaGDoD_",
        "outputId": "9895046f-467f-4300-898b-01ff685be91f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'stupid', 'sluts', 'filth', 'steglitz', 'ging', 'hillbilly', 'motherfucker', 'toter', 'damn', 'nuttensohn', 'gucci', 'sandniggers', 'cumslut', 'shuddered', 'versace-nutten', 'disgusting', 'shook', 'dick', 'crap', 'scheiß-show', 'halblang', 'nix', 'pädophile', 'weißer', 'schwuchtel-muzzie', 'flava', 'fuck-ups', 'scheiß-faker', 'thick', 'dumm', 'spitte', 'fettarsch', 'chimp', 'arsch', 'raghead', 'blöd', 'retarded', 'scheiße', 'spic', 'niggers', 'schwarze', 'piece', 'lied', 'ficken', 'rapper', 'fuckers', 'dumme', 'scheißhaut', 'gangster', 'mohammed', 'kick', 'crack-bitch', 'bonzen-slut', 'muzzie', 'dunkle', 'fm', 'zervixabstrichtests', 'faggots', 'whore', 'trottel', 'schlampe', 'slut', 'handschellen', 'washington', 'gladbach', 'pumpgun', 'shithole', 'fuck', 'bitches', 'geese', 'cuckservative', 'kike', 'verdammte', 'bitch', 'spinner', 'fucking', 'drecksratten', 'kalkarsch', 'thug', 'cocksuckers', 'scheiß', 'faggot', 'neger', 'fettfrauen', 'bullshitting', 'fuckloads', 'kikes', 'dreckskerl', 'pussy', 'cocks', 'chink', 'dumpfbacke', 'shitskins', 'hecking', 'verdammt', 'schwuchteln', 'scheißegal', 'freund', 'tochter', 'jam', 'den', 'muzzis', 'dummkopf-schlampe', 'nuts', 'arschlöcher', 'dummer', 'bullshit', 'dumb', 'faggotry', 'fick', 'nigger', 'sandnigger', 'dümmer', 'cucks', 'nigger-hure', 'mc', 'punch', 'shit', 'fagtards', 'honig', 'flambe', 'apeshit', 'cervix', 'slip'}\n"
          ]
        }
      ],
      "source": [
        "print(cmm_extracted_terms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ht1W9JfDr2k",
        "outputId": "02e24e1c-09c8-4c56-8e51-00b0ccbcff21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intersection 85\n",
            "Gold 149\n",
            "Extracted 124\n",
            "Recall: 0.5704697986577181\n",
            "Precision: 0.6854838709677419\n",
            "F1: 0.6227106227106227\n"
          ]
        }
      ],
      "source": [
        "computeTermEvalMetrics(cmm_extracted_terms, gold_set_for_cdd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EkO0f2xOFTs"
      },
      "source": [
        "# RESULTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PENPv14OG_I"
      },
      "source": [
        "## DE Only Fine-Tuned Model (DFT):\n",
        "Recall: 0.6040268456375839\n",
        "Precision: 0.7142857142857143\n",
        "**F1: 0.6545454545454547**\n",
        "\n",
        "## DE-EN Bilingual Fine-Tuned Model (DEFT):\n",
        "Recall: 0.7651006711409396\n",
        "Precision: 0.8702290076335878\n",
        "**F1: 0.8142857142857143**\n",
        "\n",
        "## Code-Switched Model (CMM):\n",
        "Recall: 0.5704697986577181\n",
        "Precision: 0.6854838709677419\n",
        "**F1: 0.6227106227106227**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JA_V32CJQCyS",
        "outputId": "3115b3c0-8dd7-498d-bd13-c0eb9491babc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------------------------------+----------------------------+----------------------------+\n",
            "| Model                                   |   F1 Score (RAP Dataset) % |   F1 Score (CDD Dataset) % |\n",
            "+=========================================+============================+============================+\n",
            "| DE Only Fine-Tuned Model (DFT)          |                      72.37 |                      65.45 |\n",
            "+-----------------------------------------+----------------------------+----------------------------+\n",
            "| DE-EN Bilingual Fine-Tuned Model (DEFT) |                      82.67 |                      81.43 |\n",
            "+-----------------------------------------+----------------------------+----------------------------+\n",
            "| Code-Mixed Model (CMM)                  |                      59.15 |                      62.27 |\n",
            "+-----------------------------------------+----------------------------+----------------------------+\n"
          ]
        }
      ],
      "source": [
        "data = {\n",
        "    \"Model\": [\n",
        "        \"DE Only Fine-Tuned Model (DFT)\",\n",
        "        \"DE-EN Bilingual Fine-Tuned Model (DEFT)\",\n",
        "        \"Code-Mixed Model (CMM)\"\n",
        "    ],\n",
        "    \"F1 Score (RAP Dataset) %\": [\n",
        "        72.37, 82.67, 59.15\n",
        "    ],\n",
        "    \"F1 Score (CDD Dataset) %\": [\n",
        "        65.45, 81.43, 62.27\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df.to_markdown(index=False, tablefmt=\"grid\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaK8Ll5LcfS1"
      },
      "source": [
        "# NEOLOGISMS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPLsKVCEeU26",
        "outputId": "07552916-6064-43b9-e6e9-68913cce473f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| Neologism         |   Detected by DFT |   Detected by CMM |   Detected by DEFT |\n",
            "|:------------------|------------------:|------------------:|-------------------:|\n",
            "| bitchbart         |                 1 |                 1 |                  1 |\n",
            "| bitchrap          |                 1 |                 1 |                  1 |\n",
            "| bitchtits         |                 1 |                 1 |                  1 |\n",
            "| boss-cock         |                 1 |                 1 |                  1 |\n",
            "| broke-ass-bitch   |                 1 |                 1 |                  1 |\n",
            "| disco-hoes        |                 0 |                 0 |                  0 |\n",
            "| dreckstoys        |                 1 |                 1 |                  1 |\n",
            "| facedrive         |                 0 |                 1 |                  0 |\n",
            "| hurenschleimer    |                 1 |                 1 |                  1 |\n",
            "| hurensohnköpfen   |                 1 |                 1 |                  1 |\n",
            "| kanackenfreestyle |                 1 |                 0 |                  1 |\n",
            "| muschibattle      |                 1 |                 1 |                  1 |\n"
          ]
        }
      ],
      "source": [
        "neologisms = [\n",
        "    \"bitchbart\", \"bitchrap\", \"bitchtits\", \"boss-cock\", \"broke-ass-bitch\",\n",
        "    \"disco-hoes\", \"dreckstoys\", \"facedrive\", \"hurenschleimer\",\n",
        "    \"hurensohnköpfen\", \"kanackenfreestyle\", \"muschibattle\"\n",
        "]\n",
        "\n",
        "detection_dft = [\n",
        "    \"bitchbart\", \"bitchrap\", \"bitchtits\", \"boss-cock\", \"broke-ass-bitch\",\n",
        "    \"dreckstoys\", \"hurenschleimer\", \"hurensohnköpfen\", \"kanackenfreestyle\",\n",
        "    \"muschibattle\"\n",
        "]\n",
        "\n",
        "detection_cmm = [\n",
        "    \"bitchbart\", \"bitchrap\", \"bitchtits\", \"boss-cock\", \"broke-ass-bitch\",\n",
        "    \"dreckstoys\", \"facedrive\", \"hurenschleimer\", \"hurensohnköpfen\", \"muschibattle\"\n",
        "]\n",
        "\n",
        "detection_deft = [\n",
        "    \"bitchbart\", \"bitchrap\", \"bitchtits\", \"boss-cock\", \"broke-ass-bitch\",\n",
        "    \"dreckstoys\", \"hurenschleimer\", \"hurensohnköpfen\", \"kanackenfreestyle\",\n",
        "    \"muschibattle\"\n",
        "]\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"Neologism\": neologisms,\n",
        "    \"Detected by DFT\": [1 if n in detection_dft else 0 for n in neologisms],\n",
        "    \"Detected by CMM\": [1 if n in detection_cmm else 0 for n in neologisms],\n",
        "    \"Detected by DEFT\": [1 if n in detection_deft else 0 for n in neologisms]\n",
        "})\n",
        "\n",
        "print(df.to_markdown(index=False))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
